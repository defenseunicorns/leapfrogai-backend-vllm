# This file was autogenerated by uv via the following command:
#    uv pip compile pyproject.toml -o requirements.txt --override overrides.txt
aioprometheus==23.12.0
    # via vllm
aiosignal==1.3.1
    # via ray
annotated-types==0.6.0
    # via pydantic
anyio==4.2.0
    # via
    #   starlette
    #   watchfiles
attrs==23.2.0
    # via
    #   jsonschema
    #   referencing
backoff==2.2.1
    # via opentelemetry-exporter-otlp-proto-grpc
certifi==2024.2.2
    # via requests
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via
    #   leapfrogai
    #   ray
    #   uvicorn
confz==2.0.1
    # via leapfrogai
cupy-cuda12x==12.1.0
    # via vllm
deprecated==1.2.14
    # via
    #   opentelemetry-api
    #   opentelemetry-exporter-otlp-proto-grpc
fastapi==0.109.2
    # via vllm
fastrlock==0.8.2
    # via cupy-cuda12x
filelock==3.13.1
    # via
    #   huggingface-hub
    #   ray
    #   torch
    #   transformers
    #   triton
frozenlist==1.4.1
    # via
    #   aiosignal
    #   ray
fsspec==2024.2.0
    # via
    #   huggingface-hub
    #   torch
googleapis-common-protos==1.62.0
    # via opentelemetry-exporter-otlp-proto-grpc
grpcio==1.60.1
    # via
    #   grpcio-health-checking
    #   grpcio-reflection
    #   leapfrogai
    #   opentelemetry-exporter-otlp-proto-grpc
grpcio-health-checking==1.60.1
    # via leapfrogai
grpcio-reflection==1.60.1
    # via leapfrogai
h11==0.14.0
    # via uvicorn
httptools==0.6.1
    # via uvicorn
huggingface-hub==0.20.3
    # via
    #   tokenizers
    #   transformers
idna==3.6
    # via
    #   anyio
    #   requests
importlib-metadata==6.11.0
    # via opentelemetry-api
jinja2==3.1.3
    # via torch
jsonschema==4.21.1
    # via ray
jsonschema-specifications==2023.12.1
    # via jsonschema
leapfrogai==0.4.0
markupsafe==2.1.5
    # via jinja2
mpmath==1.3.0
    # via sympy
msgpack==1.0.7
    # via ray
networkx==3.2.1
    # via torch
ninja==1.11.1.1
    # via vllm
numpy==1.26.4
    # via
    #   cupy-cuda12x
    #   transformers
    #   vllm
    #   xformers
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==8.9.2.26
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-nccl-cu12==2.18.1
    # via torch
nvidia-nvjitlink-cu12==12.3.101
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
opentelemetry-api==1.19.0
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-instrumentation
    #   opentelemetry-instrumentation-grpc
    #   opentelemetry-sdk
opentelemetry-exporter-otlp-proto-common==1.19.0
    # via opentelemetry-exporter-otlp-proto-grpc
opentelemetry-exporter-otlp-proto-grpc==1.19.0
opentelemetry-instrumentation==0.40b0
    # via opentelemetry-instrumentation-grpc
opentelemetry-instrumentation-grpc==0.40b0
opentelemetry-proto==1.19.0
    # via
    #   opentelemetry-exporter-otlp-proto-common
    #   opentelemetry-exporter-otlp-proto-grpc
opentelemetry-sdk==1.19.0
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-instrumentation-grpc
opentelemetry-semantic-conventions==0.40b0
    # via
    #   opentelemetry-instrumentation-grpc
    #   opentelemetry-sdk
orjson==3.9.14
    # via aioprometheus
packaging==23.2
    # via
    #   huggingface-hub
    #   ray
    #   transformers
prometheus-client==0.17.1
protobuf==4.25.3
    # via
    #   googleapis-common-protos
    #   grpcio-health-checking
    #   grpcio-reflection
    #   leapfrogai
    #   opentelemetry-proto
    #   ray
psutil==5.9.8
    # via vllm
pydantic==2.0
    # via
    #   confz
    #   fastapi
    #   huggingface-hub
    #   leapfrogai
    #   ray
    #   transformers
    #   vllm
pydantic-core==2.0.1
    # via pydantic
pynvml==11.5.0
    # via vllm
python-dotenv==1.0.1
    # via
    #   confz
    #   uvicorn
pyyaml==6.0.1
    # via
    #   confz
    #   huggingface-hub
    #   ray
    #   transformers
    #   uvicorn
quantile-python==1.1
    # via aioprometheus
ray==2.9.2
    # via vllm
referencing==0.33.0
    # via
    #   jsonschema
    #   jsonschema-specifications
regex==2023.12.25
    # via transformers
requests==2.31.0
    # via
    #   huggingface-hub
    #   ray
    #   transformers
rpds-py==0.18.0
    # via
    #   jsonschema
    #   referencing
safetensors==0.4.2
    # via transformers
sentencepiece==0.1.99
    # via vllm
setuptools==69.1.0
    # via opentelemetry-instrumentation
sniffio==1.3.0
    # via anyio
starlette==0.36.3
    # via
    #   aioprometheus
    #   fastapi
sympy==1.12
    # via torch
tokenizers==0.15.2
    # via transformers
toml==0.10.2
    # via confz
torch==2.1.2
    # via
    #   vllm
    #   xformers
tqdm==4.66.2
    # via
    #   huggingface-hub
    #   transformers
transformers==4.37.2
    # via vllm
triton==2.1.0
    # via
    #   torch
    #   vllm
typing-extensions==4.9.0
    # via
    #   fastapi
    #   huggingface-hub
    #   opentelemetry-sdk
    #   pydantic
    #   pydantic-core
    #   torch
urllib3==2.2.0
    # via requests
uvicorn==0.27.1
    # via vllm
uvloop==0.19.0
    # via uvicorn
vllm==0.3.1
watchfiles==0.21.0
    # via uvicorn
websockets==12.0
    # via uvicorn
wrapt==1.16.0
    # via
    #   deprecated
    #   opentelemetry-instrumentation
    #   opentelemetry-instrumentation-grpc
xformers==0.0.23.post1
    # via vllm
zipp==3.17.0
    # via importlib-metadata
